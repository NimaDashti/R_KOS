h=read.table(".../HEJAZI.TXT")
head(h)
str(h)
install.packages("data.table")
library(data.table)
install.packages("readxl")
library(readxl)
hx=read_excel('.../HEJAZI.xls')
str(hx)
co2=read.csv('.../data-co2.csv')
str(co2)
library(data.table)
fco2=fread('.../data-co2.csv')
head(fco2)
str(fco2)
co2[1]
fco2[1]
fco2[,1]
fco2[1,]
fco2[,'Type']
fco2[,s:=7]
fco2
fco2[,s:=runif(84)]
fco2
fco2[,m:=mean(uptake)]
fco2
fco2[,md:=uptake-m]
fco2
fco2[,smd2:=sum((uptake-m)^2)]
fco2
fco2[,md:=NULL]
fco2
fco2[,mdg:=mean(uptake),by=Plant]
fco2
fco2[,mdg2:=mean(uptake),by=Type]
fco2
fco2[,mdg2.2:=mean(uptake),keyby=Plant]
fco2
fco2[20:25,mu:=mean(uptake)]
fco2
fco2[,kk:=uptake/conc]
fco2
height=c(round(rnorm(400,160,10)))
height
weight=c(round(rnorm(400,65,10)))
weight
sex=sample(c(0,1),size=400,r=T)
sex
x=data.table(height=round(rnorm(400,160,10)),weight=round(rnorm(400,65,10)))
x
x[,sex:=sample(c(0,1),size=400,r=T)]
x
x[,bmi:=round(weight/(height/100)^2)]
x
x[,unhealth:=bmi>25]
x
x[bmi>25,unhealthy:=1]
x
x[,unhealth:=NULL]
x
x[,unh:=ifelse(bmi>25,'Unhealth','Health')]
x
x[5:15,]
x[sex==1 & unh=='Unhealth',]
x[sex==1 & unhealth,]
x[sex==1 & !unhealth,]
x[,mean(height)]
x[,mean(weight)]
x[,mean(height),by=unhealth]
x[,mean(height),by=unh]
x[,mean(weight),by=unh]
x[,mh:=mean(height),by=unh]
x
x[,mh:=mean(height),by=unhealth]
x[,plot(height,weight),by=unh]
x[,plot(height,weight)]
X11(x[,plot(height,weight)])
savePlot('test2.jpg',type = 'jpg')
or
jpeg('test3.jpg')
x[,plot(height,weight)]
dev.off()

pdf('test4.pdf')
x[,plot(height,bmi)]
dev.off()

par(mfrow=c(2,1))
X11(x[,plot(height,weight),by=unhealth])

par(mfrow=c(1,1))
X11(x[,plot(height,weight,col=unhealth+3)])


h1=read.table(".../HEJAZI.TXT")
head(h1)
library(readxl)
h2=read_excel('.../HEJAZI.xls',col_names = F)
head(h2)
h1$V4
h2$...4
colnames(h2)=paste('c',1:31)
colnames(h2)
colnames(h2)=paste0('c',1:31)
colnames(h2)
h2$c4
library(data.table)
hd=data.table(h1)
head(hd)
dim(hd)
mean(h1$V4)
hd[,mean(V4)]
hd[,mean(V4),by=V1]
hd[,plot(V4,V6)]
hd[,hist(V4)]
hd[,hist(V4)]

par(mfrow=c(2,2))
hd[,pie(V4,col="maroon",), by=V1]
hd[,.(boxplot(V4)),by=V1]
hd[,.(hist(V4)),by=V1]
#or
for(i in 1:4) hd[V1==i,hist(V4)]

par(mfrow=c(1,1))
hd[V1==1,hist(V4)]

for(i in 1:4){
  jpeg('i.jpg');
  hd[V1==i,hist(V4)];
  dev.off()
}

k=3
paste(k,'aaaa')
k=1
paste(k,'jpg')
i=1
paste(i,'jpg',sep ='.')

for(i in 1:4){
  jpeg(paste(i,'jpg',sep ='.'));
  hd[V1==i,hist(V4)];
  dev.off()
}

unique(hd$V1)
unique(hd$V2)

for(i in unique(hd$V1)){
  jpeg(paste(i,'jpg',sep ='.'));
  hd[V1==i,hist(V4)];
  dev.off()
}

for(i in unique(hd$V2)){
  jpeg(paste(i,'jpg',sep ='.'));
  hd[V2==i,hist(V7)];
  dev.off()
}
for(i in unique(hd$V2)){
  jpeg(paste(i,'jpg',sep ='.'));
  hd[V2==i,boxplot(V7)];
  dev.off()
}
for(i in unique(hd$V2)){
  jpeg(paste(i,'jpg',sep ='.'));
  hd[V2==i,.(boxplot(V7))];
  dev.off()
}

?data.table

for(i in unique(hd$V1)){
  jpeg(paste(i,'jpg',sep ='.'));
  hd[V1==i,plot(V6,V21)];
  dev.off()
}

x=c(12,13,14,15,12,12,12,14,14)
y=c(4,5,6,4,5,3,4,2,4)
plot(x,y)
lm(y~x)$coef
coef(lm(y~x))
plot(x,y,main=paste('Intercept:',round(coef(lm(y~x))[1],4),',slope:',round(coef(lm(y~x))[2],4)))

for(i in unique(hd$V1)){
  jpeg(paste(i,'jpg',sep="."))
  hd[V1==i, plot(V6,V21,col="maroon",main=paste('Intecept:',round(coef(lm(hd$V6~hd$V21))[1],4),'Slope:',round(coef(lm(hd$V6~hd$V21))[2],4)))]
  dev.off()
}

install.packages("data.table")
library(data.table)
h3=fread('.../CAR DETAILS FROM CAR DEKHO.csv')
head(h3)
str(h3)
ncol(h3)
nrow(h3)
dim(h3)

#3

sapply(h3,mode)
table(sapply(h3,mode))
sum(sapply(h3,mode)=='character')

#4

mean(h3$year)
mean(h3$selling_price)
mean(h3$km_driven)

median(h3$year)
median(h3$selling_price)
median(h3$km_driven)

summary(h3)

var(h3$year)
var(h3$selling_price)
var(h3$km_driven)

diag(var(h3[,2:4]))
diag(var(h3[,sapply(h3,mode)=='numeric']))
b=sapply(h3,function(x)mode(x)=='numeric')
(1:ncol(h3))[b]
paste((1:ncol(h3))[b],collapse=',')
paste('c(',paste((1:ncol(h3))[b],collapse=','),')')
paste("diag(var(h3[," , paste("c(",paste((1:ncol(h3))[b] ,collapse=","),")"), "]))")
eval(parse(text=paste("diag(var(h3[," , paste("c(",paste((1:ncol(h3))[b] ,collapse=","),")")
, "]))")))



hb=data.table(h3)
hb
dim(hb)

hb[,median(selling_price),by=fuel]

hb[,plot(selling_price,km_driven,col="maroon",main=paste('Intecept:',round(coef(lm(hb$selling_price~hb$year))[1]),'Slope:',round(coef(lm(hb$selling_price~hb$year))[2])))]
par(mfrow=c(1,5))
hb[,plot( year , selling_price ,col="maroon",main=paste('Intecept:',round(coef(lm(hb$selling_price~hb$year))[1]),'Slope:',round(coef(lm(hb$selling_price~hb$year))[2]))),by=fuel]
hb[,plot(selling_price,km_driven,col="maroon",main=paste('Intecept:',round(coef(lm(hb$selling_price~hb$year))[1]),'Slope:',round(coef(lm(hb$selling_price~hb$year))[2])))]


hb[,Sqr:=sqrt(selling_price)]
hb
hb[,sqrt_root:=ifelse(Sqr < mean(km_driven),Sqr , NA)]
hb

sum( is.na(hb$sqrt_root) )


#Data Covid

#1

install.packages("data.table")
library(data.table)
cv=fread('E:/FUM/ارشد/ترم3/محاسبات 2/owid-covid-data.csv')
head(cv)

#2

dim(cv)

#3

table(sapply(cv,mode))
sum((sapply(cv,mode))=='character')

#4

summary(cv)

nn=names(cv)[sapply(cv,mode)=='numeric']
k=c();for(i in nn) k=c(k,eval(parse(text=paste('cv[,var(',i,',na.rm=T)]'))))
names(k)=nn
k
boxplot(k,las=2)
#5

names(cv)[sapply(cv,mode)=='numeric'][2]
names(cv)[sapply(cv,mode)=='character'][2]
cv[,median(total_cases,na.rm=T),by=continent]

#6

cv[,plot(total_cases,total_deaths,col=4,
         main=paste('Intecept:',round(coef(lm(cv$total_cases~cv$total_deaths))[1]),
                    'Slope:',round(coef(lm(cv$total_cases~cv$total_deaths))[2])))]

#7

par(mfrow=c(2,4))
cv[,plot(total_cases,total_deaths,col="maroon",
        main=paste('intercept:',round(coef(lm(total_cases~total_deaths))[1]),
                   'slope:',round(coef(lm(total_cases~total_deaths))[2]))),by=continent]

#8

names(cv)[sapply(cv,mode)=='numeric'][2]
names(cv)[sapply(cv,mode)=='numeric'][3]
cv[new_cases < mean(new_cases,na.rm=T),ss:=sqrt(total_cases)]

#9

sum(is.na(cv$ss))

#10

cv[,max(total_cases,na.rm=T),by=continent]

#11

par(mfrow=c(1,2))
pie(table(cv$continent))
barplot(table(cv$continent),las=2,horiz=T)

#12

names(Filter(function(x) x > 1, table(cv$name)))
sum(table(cv$...>1)

install.packages("openxlsx")

#23/08/1401

install.packages("officer")
library(officer)
library(dplyr)

#Word

shetab_report<-read_docx()%>%
  body_end_section_continuous()
for (i in unique(a$major)){
  shetab_report<-
    body_add_fpar(shetab_report,fpar('...',fp_p=fp_par(text.align = "right")))
  shetab_report<-
    body_add_fpar(shetab_report,fpar('...',fp_par=fp_par(text.align = "right")))
  shetab_report<-
    body_add_fpar(shetab_report,fpar('...',fp_p=fp_par(text.align = "right")))
  shetab_report<-
    body_add_table()
  shetab_report<-
    body_add_break()
}

test=read_docx()
test=body_add_fpar(test,fpar('This is a test.'))
test=body_add_fpar(test,fpar(''))
test=body_add_fpar(test,fpar('.....',fp_p=fp_par(text.align = "right")))
test=body_add_fpar(test,fpar(''))
y=rnorm(25)
x=rnorm(25)
z=data.frame(x,y)
test=body_add_table(test,z)
test=test%>%
  body_add_break()
test=body_add_fpar(test,fpar('....',fp_p=fp_par(text.align = "right")))
test=body_add_plot(test,plot(x,y,col=5))
test=body_add_fpar(test,fpar(''))
test=body_add_fpar(test,fpar('The end'))
print(test,target='.../Nima2.docx')

for(i in 1:1000){
  jpeg(paste('.../new',i,'jpg',sep =''));
  hist(rnorm(100));
  dev.off()
}

#Word_D

install.packages("readxl")
library(readxl)
install.packages("officer")
library(officer)
library(dplyr)
my=read_excel('E:/FUM/ارشد/ترم3/محاسبات 2/mydata.xlsx')
Dashti=read_docx()
Dashti=body_add_fpar(Dashti,fpar('نمودار پراکنش هفته اول در مقابل هفته دوم',fp_p=fp_par(text.align = "right")))
Dashti=body_add_fpar(Dashti,fpar(''))
W1=my[,1]
W2=my[,2]
z=data.frame(W1,W2)
Dashti=body_add_plot(Dashti,plot(z,col=5))
Dashti=Dashti%>%
  body_add_break()
Dashti=body_add_fpar(Dashti,fpar('مقادیر باقیمانده خط رگرسیون هفته اول بر وزن',fp_p=fp_par(text.align = "right")))
Dashti=body_add_fpar(Dashti,fpar(''))
W1=unlist(W1)
W1=as.vector(W1,'numeric')
Dashti=body_add(Dashti,lm(my$weight~W1)$res)
Dashti=Dashti%>%
  body_add_break()
Dashti=body_add_fpar(Dashti,fpar('رسم جدول فراوانی برای کشور ',fp_p=fp_par(text.align = "right")))
Dashti=body_add_fpar(Dashti,fpar(''))
n=data.frame(table(my$country)) 
Dashti=body_add_table(Dashti,n)
print(Dashti,target='E:/FUM/ارشد/ترم3/محاسبات 2/Dashti2.docx')


#Power_point

doc_1 <- read_pptx()
doc_1 <- add_slide(doc_1, layout = "Two Content", master = "Office Theme")
doc_1 <- ph_with(x = doc_1, value = c("Table cars"),    location = ph_location_type(type = "title") )
doc_1 <- ph_with(x = doc_1, value = names(cars),    location = ph_location_left() )
doc_1 <- ph_with(x = doc_1, value = cars,    location = ph_location_right() )
anyplot <- plot_instr(code = {
  col <- c("#440154FF", "#443A83FF", "#31688EFF",
                      "#21908CFF", "#35B779FF", "#8FD744FF", "#FDE725FF")
                      barplot(1:7, col = col, yaxt="n")
})

doc_1 <- add_slide(doc_1)
doc_1 <- ph_with( doc_1, anyplot,   location = ph_location_fullsize(),   bg = "#006699")
print(doc_1,'E:/FUM/ارشد/ترم3/محاسبات 2/test.pptx')

#Power_point_D

library(httr)
library(jsonlite)
library(officer)
q=GET("https://open.er-api.com/v6/latest/USD")
data=fromJSON(rawToChar(q$content))
y=unlist(data$rates)

test1=read_pptx()
test1=add_slide(test1, layout = "Two Content", master = "Office Theme")
test1=ph_with(x = test1, value = c("..."), location = ph_location_type(type = "title") )
test1=ph_with(x = test1, value = names(data), location = ph_location_left() )
test1=add_slide(test1, layout = "Two Content", master = "Office Theme")
test1=ph_with(x = test1, value = c("..."), location = ph_location_type(type = "title") )
test1=ph_with(x = test1, value = head(names(y)), location = ph_location_left())
test1=ph_with(x = test1, value = head(y), location = ph_location_right())
anyplot <- plot_instr(code = {
  col <- c("#440154FF", "#443A83FF", "#31688EFF",
                      "#21908CFF", "#35B779FF", "#8FD744FF", "#FDE725FF")
                      hist(y, col = col, yaxt="n")
})
test1=add_slide(test1)
test1=ph_with( test1, anyplot, location = ph_location_fullsize(), bg = "#006699")
anyplot <- plot_instr(code = {
  col <- c("#440154FF", "#443A83FF", "#31688EFF",
                      "#21908CFF", "#35B779FF", "#8FD744FF", "#FDE725FF")
                      pie(y, col = col, yaxt="n")
})
test1=add_slide(test1)
test1=ph_with( test1, anyplot, location = ph_location_fullsize(), bg = "#006699")
anyplot <- plot_instr(code = {
  col <- c("#440154FF", "#443A83FF", "#31688EFF",
                      "#21908CFF", "#35B779FF", "#8FD744FF", "#FDE725FF")
                      barplot(y, col = col,las=2, yaxt="n")
})
test1=add_slide(test1)
test1=ph_with( test1, anyplot, location = ph_location_fullsize(), bg = "#006699")

print(test1,'.../test1.pptx')

#Power_point_A

a=GET("https://open.er-api.com/v6/latest/USD")
b=rawToChar(a$content)
x=fromJSON(b)
y=unlist(x$rates)

test2 <- read_pptx()
test2 <- add_slide(test2, layout = "Title and Content", master = "Office Theme")

#This call gives us the population of the US based on the latest available year of data.

test2 <- ph_with(x = test2, value = c('data from "https://open.er-api.com/v6/latest/USD"','The data section of the JSON result contains an object for each row of data.',' By default, the API returns as many years possible from the data. To only retrieve the latest year’s data, use:

https://datausa.io/api/data?drilldowns=Nation&measures=Population&year=latest'),    location = ph_location_type(type = "body") )

test2 <- add_slide(test2, layout = "Two Content", master = "Office Theme")
test2 <- ph_with(x = test2, value = c("Exchange Rate API"),    location = ph_location_type(type = "title") )
test2 <- ph_with(x = test2, value = head(names(y)),    location = ph_location_left() )
test2 <- ph_with(x = test2, value =head( y),    location = ph_location_right() )
anyplot <- plot_instr(code = {
  col <- c("#440154FF", "#443A83FF", "#31688EFF",
                      "#21908CFF", "#35B779FF", "#8FD744FF", "#FDE725FF")
                      hist(y, col = col, yaxt="n")
})
anyplot1 <- plot_instr(code = {
  col <- c("#440154FF", "#443A83FF", "#31688EFF",
                      "#21908CFF", "#35B779FF", "#8FD744FF", "#FDE725FF")
                      boxplot(y, col = col, yaxt="n")
})

test2 <- add_slide(test2)
test2 <- ph_with( test2, anyplot1,   location = ph_location_fullsize(),   bg = "#014214")


test2 <- add_slide(test2)
test2 <- ph_with( test2, anyplot,   location = ph_location_fullsize(),   bg = "#006699")
print(test2,'.../test2.pptx')

#Power_point_H 

library(robustbase)
library(httr)
library(jsonlite)

a=GET("https://open.er-api.com/v6/latest/USD")
b=rawToChar(a$content)
x=fromJSON(b)
y=unlist(x$rates)

pp_2 <- read_pptx()
pp_2 <- add_slide(pp_2, layout = "Two Content", master = "Office Theme")
pp_2 <- ph_with(x = pp_2, value = c("Exchange Rate API"),    location = ph_location_type(type = "title") )
pp_2 <- ph_with(x = pp_2, value = head(names(y)),    location = ph_location_left() )
pp_2 <- ph_with(x = pp_2, value = head(y),    location = ph_location_right() )
anyplot <- plot_instr(code = {
  col <- c("#440154FF", "#443A83FF", "#31688EFF",
                      "#21908CFF", "#35B779FF", "#8FD744FF", "#FDE725FF")
                      hist(y, col = col, yaxt="n")
}) 
pp_2 <- add_slide(pp_2)
pp_2 <- ph_with( pp_2, anyplot,   location = ph_location_fullsize(),   bg = "#006699")
anyplot <- plot_instr(code = {
  boxplot(y, yaxt="n")
}) 
pp_2 <- add_slide(pp_2)	
pp_2 <- ph_with( pp_2, anyplot,   location = ph_location_fullsize(),   bg = "#006699")
print(pp_2,'C:\\Users\\4001395100\\Desktop\\test3.pptx')



library(Rcmdr)




install.packages("BiocManager")
??BiocManager
BiocManager::install('rhdf5')
library(rhdf5)
h5ls(file.choose())
h5dump(file.choose())
k=h5dump(file.choose())
mode(k)
class(k)
names(k)
k$ap
names(k$ap)
mode(k$ap)
mode(k$ap$data)
dim(k$ap$data)
length(k$ap$data)

write.csv(k$ap$data,'.../ap-data.csv')
write.csv(k$tt$data,'.../tt-data.csv')
write.csv(k$mg$data,'.../mg-data.csv')

install.packages('openxlsx')
library(openxlsx)
setwd('.../')
write.xlsx(data.frame(k$ap$data),'ap.xlsx',sheet=1)
write.xlsx(data.frame(k$mg$data),'ap.xlsx',Sheet=2)

h=createWorkbook('a')
addWorksheet(h,'data')
addWorksheet(h,'indices')
addWorksheet(h,'indptr')
writeData(h,sheet=1,data.frame(k$ap$data))
writeData(h,sheet=2,data.frame(k$ap$indices))
writeData(h,sheet=3,data.frame(k$ap$indptr))
saveWorkbook(h,'ap.xlsx')

a=k$ap$data
b=k$tt$data
var.test(a,b)
t.test(a,b,Var=F)
t.test(a)
t.test(b)

install.packages('HDtest')
library(HDtest)
twoMeans(k$ap$data,k$tt$data)
HDtest :: testMean(a,b)



library(rhdf5)
h5ls(file.choose())
h5dump(file.choose())
k=h5dump(file.choose())
mode(k)
class(k)
names(k)
k$ap
names(k$ap)
mode(k$ap)
mode(k$ap$data)
dim(k$ap$data)
length(k$ap$data)
hist(k$ap$data,col=3)
boxplot(k$ap$data,col=3)

install.packages("robustbase")
library(robustbase)
adjbox(k$ap$data,col=4)


install.packages("rjson")
library(rjson)
mm=fromJSON(file=".../Sample Json File with 500 Records.json")
mm=fromJSON(file=file.choose())
mm
print(mm)

install.packages("jsonlite")
library(jsonlite)
a=read_json(file.choose(),simplifyVector = T)
a
names(a)
a$feeds
names(a$feeds)
sapply(a$feeds, mode)
dim(a$feeds)
a$feeds$commentCount
table(a$feeds$commentCount)
boxplot(a$feeds$commentCount)
a$feeds$multiMedia
a$feeds$multiMedia[[1]]

#read_json(https:/dummy.restapiexample.com/api/v1/employees)

install.packages(c("httr", "jsonlite"))
library(httr)
library(jsonlite)
q=GET("https:/dummy.restapiexample.com/api/v1/employees")
q
rawToChar(q$content)
data=fromJSON(rawToChar(q$content))
data
names(data)
data$status
data$data
data$message



q=GET("https://open.er-api.com/v6/latest/USD")
q
q$content
mode(q$content)
rawToChar(q$content)
data=fromJSON(rawToChar(q$content))
data
mode(data)
names(data)
data$rates
mode(data$rates)
class(data$rates)
y=unlist(data$rates)
mode(y)
hist(y)
summary(y)
which.max(y)
which.min(y)
length(y)
sort(y)[2]
sort(y,d=T)[2]

which.max(y<42028.62)
sort(y)[length(sort(y))-1]
which((sort(y) == data$rates$EUR),T)
(sort(y) == data$rates$EUR)[15]
which.max(names(sort(y))=="EUR")
sort(y)[15]

k <- function(x){
  if (!is.character(x)) return("x must be character!")
  which.max(names(sort(y)) == x )
}
k("EUR")


g <- function(x){
  if(!is.character(x)) return("x must be character!")
  n <-which.max(names(sort(y)) == x )
  m <-sort(y)[n]
  print(c(n,m))
}
g("EUR")
data$rates["EUR"]

dput(k,'sssss')
k <- dget('sssss')
k

s <- function(x){
  library(httr)
  library(jsonlite)
  q=GET("https://open.er-api.com/v6/latest/USD")
  data=fromJSON(rawToChar(q$content))
  y=unlist(data$rates)
  if(!is.character(x)) return("x must be character!")
  n <-which.max(names(sort(y)) == x )
  m <-sort(y)[n]
  print(c(n,m))
}
s("EUR")



install.packages("snow")
library(snow)
install.packages("rlecuyer")
library(rlecuyer)
cl=makeCluster(2)
cl=makeCluster(c('localhost','localhost'))
clusterSetupRNG(cl)
clusterCall(cl,runif,5)
stopCluster(cl)
clusterSetupRNG(cl,seed=runif(2)*1e7)
clusterCall(cl,runif,5)
mean(replicate(100,sum(sample(6,5,v=T))<20))
m <- function(h) mean(replicate(h,sum(sample(1:6,5,r=T))<20))
m(1000000)
k <- makeCluster(4)
clusterSetupRNG(k)
clusterCall(k,m,250000)
s <- clusterCall(k,m,250000)
mean(unlist(s))

#.......

install.packages("biglm")
library(biglm)
?bigglm
A=matrix(1:4,50000000,4)
c1=A[1:10000000,]
c2=A[10000001:20000000,]
c3=A[20000001:30000000,]
c4=A[30000001:40000000,]
c5=A[40000001:50000000,]
a=biglm(y~ . ,data=c1)
a=update(a,c2)
a=update(a,c3)
a=update(a,c4)
a=update(a,c5)
summary(a)

#....NO

library(biglm)
library(DBI)
data(trees)
str(trees)
ff<-log(Volume)~log(Girth)+log(Height)
chunk1<-trees[1:10,]
chunk2<-trees[11:20,]
chunk3<-trees[21:31,]
a <- biglm(ff,chunk1)
a <- update(a,chunk2)
a <- update(a,chunk3)
summary(a)
deviance(a)
AIC(a)

library(data.table)

#Data_sunfrans

a=fread(file.choose())
dim(a)
str(a)
nrow(a)
for (i in seq(1,nrow(a),5000)) print(i)
for (i in seq(1,nrow(a),5000)) cat(i)
j=c(seq(1,nrow(a),5000),nrow(a)+1)
1:length(j)
for(i in 1:(length(j)-1))
  eval(parse(text=paste('c',i,'=a[',j[i],':',j[i+1]-1,',]',sep='')
  ))
ls()
names(a)
str(a)
names(a)[5:10]
eval(parse(text=paste('k=biglm(',names(a)[10],'~',paste(names(a)[5:9],collapse='+'),',c1)'))
)
for(i in 2:(length(j)-1))
  eval(parse(text=paste('k=update(k,c',i,')',sep='')
  ))
summary(k)


#....No

a <- scan(w=list(""),file="C:/Users/4001395304/Desktop/bm.txt",n=1000000,skip=16000000)
grep('e',a[[1]])
grep('[a-z]',a[[1]])
a[[1]][33288]
a[[1]][996300]
library(data.table)
b <- fread('C:/Users/4001395304/Desktop/bm.txt',nrow=10000000)
b <- fread('C:/Users/4001395304/Desktop/bm.txt',nrow=10000000,skip=10000000)
b <- fread('C:/Users/4001395304/Desktop/bm.txt',nrow=10000000,skip=20000000)
b <- fread('C:/Users/4001395304/Desktop/bm.txt',nrow=1000000,skip=17000000)
b <- fread('C:/Users/4001395304/Desktop/bm.txt',nrow=80000,skip=17500000)
a <- scan(w=list(""),file="C:/Users/4001395304/Desktop/bm.txt",n=80000,skip=17500000)
grep('[a-z]',a[[1]])
a[[1]][77804]
a[[1]][77812]
a[[1]][77813]

a1 <- fread('E:/FUM/ارشد/ترم3/محاسبات 2/bm.txt',nrow=1e7)
a2 <- fread('E:/FUM/ارشد/ترم3/محاسبات 2/bm.txt',nrow=1e7,skip=2e7)
a3 <- fread('E:/FUM/ارشد/ترم3/محاسبات 2/bm.txt',nrow=1e7,skip=3e7)
aa <- rbind(a1,a2,a3,use.names=FALSE)
aa
str(aa)
attach(aa)
lm(aa$y~aa$x)
summary(lm(aa$y~aa$x))
hist(unlist(aa[,1]))
v1 <- unlist(aa[,1])
v2 <- unlist(aa[,2])
v3 <- unlist(aa[,3])
plot(v1,v2)

#...no

install.packages("data.table")
library(data.table)
a <- fread(file=".../bm.txt")
install.packages("hexbin")
library(hexbin)
plot(hexbin(a$x,a$y))
system.time(plot(hexbin(a$x,a$y)))
str(a)
biglm(y~x+z,data = a)
summary(biglm(y~x+z,data = a))
system.time(summary(biglm(y~x+z,data = a)))

install.packages("biganalytics")
library(biganalytics)
y=matrix(0,100000,300)
s=sample(100000,40000)
y[s,]=rnorm(40000*300)
y[-s,]=rnorm(60000*300,5,2)
system.time(yy<-kmeans(y,2))
x=as.big.matrix(y)
system.time(xx<-bigkmeans(x,2))
head(yy$cluster)
head(xx$cluster)
head(sort(s))
table(yy$cluster,xx$cluster)
sum(yy$cluster-xx$cluster)
system.time(sum(yy$cluster-xx$cluster))
sum(yy$cluster!=xx$cluster)
system.time(sum(yy$cluster!=xx$cluster))
system.time(sum(yy$cluster-xx$cluster))[3]/system.time(sum(yy$cluster!=xx$cluster))[3]

y=matrix(0,1000000,300)
s=sample(1000000,400000)
y[s,]=rnorm(400000*300)
y[-s,]=rnorm(600000*300,5,2)
system.time(yy<-kmeans(y,2))
x=as.big.matrix(y)
system.time(xx<-bigkmeans(x,2))


install.packages("ff")
library(ff)
sample(1e8,10)
for (i in 1:1000) sample(1e8 ,10)
system.time(for (i in 1:100) sample(1e8 ,10000))/
  system.time(for (i in 1:100) bigsample(1e8 ,10000))

